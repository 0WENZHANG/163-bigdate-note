## 安装logstash

1. 下载[logstash2.4.1](https://download.elastic.co/logstash/logstash/logstash-2.4.1.tar.gz).

2. 解压到 `/opt/sxt` 目录下。

    ```
    [root@node01 packages]# tar xzvf logstash-2.4.1.tar.gz -C /opt/sxt/
    ```
3. 测试logstash

    使用默认格式，直接以终端为输入输出：

    ```
    [root@node01 sxt]# cd logstash-2.4.1/
    [root@node01 logstash-2.4.1]# bin/logstash -e 'input { stdin { } } output { stdout {} }'
    Settings: Default pipeline workers: 1
    Pipeline main started
    hello
    2019-04-10T06:08:17.418Z node01 hello
    test
    2019-04-10T06:08:20.593Z node01 test
    ```

    使用 json 格式，以终端为输入输出：

    ```
    [root@node01 logstash-2.4.1]# bin/logstash -e 'input { stdin { } } output { stdout {codec => json} }'
    Settings: Default pipeline workers: 1
    Pipeline main started
    hello
    {"message":"hello","@version":"1","@timestamp":"2019-04-10T06:10:53.811Z","host":"node01"}world
    {"message":"world","@version":"1","@timestamp":"2019-04-10T06:10:57.058Z","host":"node01"}
    ```

    编写配置文件 `test.conf`：

    ```
    input { 
        stdin { } 
    } 

    output { 
        stdout {
            codec => json
        } 
    }
    ```

    ```
    [root@node01 logstash-2.4.1]# bin/logstash -f conf/test.conf 
    Settings: Default pipeline workers: 1
    Pipeline main started
    hello
    {"message":"hello","@version":"1","@timestamp":"2019-04-10T06:17:30.724Z","host":"node01"}world
    {"message":"world","@version":"1","@timestamp":"2019-04-10T06:17:33.243Z","host":"node01"}
    ```

4. 监控指定文件

    conf 文件如下：

    ```
    input {
        file {
            path => "/opt/sxt/logstash-2.4.1/data/log"
        }
    }

    output {
        stdout {
            codec => json
        }
    }
    ```

    运行：

    ```
    [root@node01 logstash-2.4.1]# bin/logstash -f conf/file_stdout.conf 
    Settings: Default pipeline workers: 1
    Pipeline main started
    ```
 
    在其他终端给 `/opt/sxt/logstash-2.4.1/data/log` 文件追加内容：

    ```
    [root@node01 data]# echo "hello" >> log 
    [root@node01 data]# echo "world" >> log
    ```

    ```
    {"message":"hello","@version":"1","@timestamp":"2019-04-10T06:26:47.888Z","path":"/opt/sxt/logstash-2.4.1/data/log","host":"node01"}{"message":"world","@version":"1","@timestamp":"2019-04-10T06:27:08.121Z","path":"/opt/sxt/logstash-2.4.1/data/log","host":"node01"}
    ```

## Kafka

1. 下载 Kafka：[kafka_2.11-0.9.0.0.tgz](https://archive.apache.org/dist/kafka/0.9.0.0/kafka_2.11-0.9.0.0.tgz)。

2. 解压到指定目录，并配置环境变量

    解压：

    ```
    [root@node01 config]# tar xzvf kafka_2.11-0.9.0.0.tgz -C /opt/sxt/
    ```

    配置环境变量：

    ```
    # Kafka
    export KAFKA_HOME=/opt/sxt/kafka_2.11-0.9.0.0
    export PATH=$KAFKA_HOME/bin:$PATH
    ```

3. 修改配置文件

    ```
    broker.id=0
    host.name=node01
    log.dirs=/var/sxt/kafka-logs
    zookeeper.connect=node02:2181,node03:2181,node04:2181
    ```    

4. 启动

    先启动 ZooKeeper：
    
    ```
    [root@node02 conf]# zkServer.sh start
    [root@node03 conf]# zkServer.sh start
    [root@node04 conf]# zkServer.sh start
    ```

    再启动 kafka：

    ```
    [root@node01 bin]# kafka-server-start.sh /opt/sxt/kafka_2.11-0.9.0.0/config/server.properties 
    ```

    创建 topic 指定 ZooKeeper：

    ```
    [root@node01 kafka-logs]# kafka-topics.sh --create --zookeeper node02:2181 --replication-factor 1 --partitions 1 --topic test
    Created topic "test".
    [root@node01 kafka-logs]# kafka-topics.sh --list --zookeeper node02:2181
    test
    ```

    可以看到已经正确创建了topic。

    发送消息：指定 broker

    ```
    [root@node01 kafka-logs]# kafka-console-producer.sh --broker-list node01:9092 --topic test
    ```

    接收消息：指定ZooKeeper

    ```
    [root@node01 sxt]# kafka-console-consumer.sh --zookeeper node02:2181 --topic test --from-beginning
    ```

    查看指定 topic 的详细信息：

    ```
    [root@node01 ~]# kafka-topics.sh --describe --zookeeper node03:2181 --topic test
    Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
        Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
    ```

5. 单节点多 brokers 配置：

    复制多分配置文件：

    ```
    [root@node01 config]# cp server.properties server-1.properties 
    [root@node01 config]# cp server.properties server-2.properties 
    [root@node01 config]# cp server.properties server-3.properties
    ```

    修改配置文件内容：

    ```
    # server-1.properties
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/var/sxt/kafka-logs-1

    # server-2.properties
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/var/sxt/kafka-logs-2

    # server-3.properties
    broker.id=3
    listeners=PLAINTEXT://:9095
    log.dirs=/var/sxt/kafka-logs-3
    ```

    启动 kafka，由于我的机器内存分配了1G，默认情况下依次只能启动一个Kafka，先设置一个变量，[参考链接](https://blog.csdn.net/gywtzh0889/article/details/51773536)：

    ```
    export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M"
    ```

    ```
    kafka-server-start.sh -daemon /opt/sxt/kafka_2.11-0.9.0.0/config/server-1.properties &
    kafka-server-start.sh -daemon /opt/sxt/kafka_2.11-0.9.0.0/config/server-2.properties &
    kafka-server-start.sh -daemon /opt/sxt/kafka_2.11-0.9.0.0/config/server-3.properties &
    ```

    创建topic：

    ```
    [root@node01 config]# kafka-topics.sh --create --zookeeper node02:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
    Created topic "my-replicated-topic".
    ```

    查看 topic：

    ```
    [root@node01 config]# kafka-topics.sh --list --zookeeper node02:2181
    my-replicated-topic
    test
    [root@node01 config]# kafka-topics.sh --describe --zookeeper node02:2181 --topic my-replicated-topic
    Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
        Topic: my-replicated-topic	Partition: 0	Leader: 3	Replicas: 3,2,1	Isr: 1,3,2
    ```

    发送消息测试：

    ```
    kafka-console-producer.sh --broker-list node01:9093,node01:9094,node01:9095 --topic my-replicated-topic
    ```

    接收消息，在多个终端开启 Kafka：

    ```
    kafka-console-consumer.sh --zookeeper node02:2181 --topic my-replicated-topic
    ```

    ```
    kafka-console-consumer.sh --zookeeper node02:2181 --topic my-replicated-topic
    ```

    在发送消息框输入发送的信息，查看 consumer 中是否收到。

## LogStash 与 Kafka整合

1. 先启动 zookeeper

    ```
    [root@node02 conf]# zkServer.sh start
    [root@node03 conf]# zkServer.sh start
    [root@node04 conf]# zkServer.sh start
    ```

2. 启动 Kafka：

    ```
    kafka-server-start.sh -daemon /opt/sxt/kafka_2.11-0.9.0.0/config/server.properties &
    ```

    创建一个 topic：

    ```
    [root@node01 ~]# kafka-topics.sh --create --zookeeper node02:2181 --replication-factor 1 --partitions 1 --topic logstash_topic
    WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
    Created topic "logstash_topic".
    [root@node01 ~]# kafka-topics.sh --list --zookeeper node02:2181
    logstash_topic
    my-replicated-topic
    test
    ```

    创建生产者：

    ```
    [root@node01 ~]# kafka-console-producer.sh --broker-list node01:9092 --topic logstash_topic
    ```

    创建消费者：

    ```
    [root@node01 kafka-logs]# kafka-console-consumer.sh --zookeeper node02:2181 -topic logstash_topic
    ```

3. 整合 logstash 的数据到 kafka：

    编写 logstash 配置文件：

    ```
    input {
        file {
            path => "/opt/sxt/logstash-2.4.1/data/log"
        }
    }

    output {
        kafka { 
            topic_id => logstash_topic
            bootstrap_servers => "node01:9092"
            batch_size => 1
        }
    }
    ```

    启动 logstash

    ```
    [root@node01 logstash-2.4.1]# bin/logstash -f conf/file_kafka.conf 
    Settings: Default pipeline workers: 1
    Pipeline main started
    ```

    启动 kafka 消费者：

    ```
    [root@node01 kafka-logs]# kafka-console-consumer.sh --zookeeper node02:2181 -topic logstash_topic
    ```

    在 logstash 监控的文件 `/opt/sxt/logstash-2.4.1/data/log` 中添加内容，观察 kafka 中有没有消息产生：

    ```
    [root@node01 data]# echo "hello" >> log
    [root@node01 data]# echo "hello world" >> log
    ```

    从下面的输出可以看到 kafka正确收到了 logstash 收集到的消息:
    ```
    [root@node01 kafka-logs]# kafka-console-consumer.sh --zookeeper node02:2181 -topic logstash_topic
    hello
    {"message":"hello","@version":"1","@timestamp":"2019-04-10T08:50:44.421Z","path":"/opt/sxt/logstash-2.4.1/data/log","host":"node01"}
    {"message":"hello world","@version":"1","@timestamp":"2019-04-10T08:51:46.483Z","path":"/opt/sxt/logstash-2.4.1/data/log","host":"node01"}
    ```


