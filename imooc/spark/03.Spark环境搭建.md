## local模式

很简单，直接解压 spark-2.1.0-bin-2.6.0-cdh5.7.0.tgz 文件，然后运行：

```
spark-shell --master "local[2]"
```

## standalone 模式

1. 拷贝 conf 目录下的 spark-env.sh.template 为 spark-env.sh，修改 spark-env.sh 的内容：

    ```conf
    JAVA_HOME=/opt/sxt/jdk1.8.0_201
    SPARK_MASTER_HOST=node01
    SPARK_WORKER_CORES=2
    SPARK_WORKER_MEMORY=2g
    SPARK_WORKER_INSTANCES=2
    ```

2. 启动 spark：

    ```
    ./start-all.sh
    ```

3. 启动 spark-shell：

    ```
    spark-shell --master spark://node01:7077
    ```

4. 在浏览器中输入 `http://192.168.60.21:8080/`，查看 spark 作业信息。

