## 下载 Hive

Hive1.1.0 下载地址：[hive-1.1.0-cdh5.7.0.tar.gz](http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.7.0.tar.gz)

## 安装

1. 加压配置环境变量

    ```conf
    # Hive
    export HIVE_HOME=/home/wst/apps/hive-1.1.0-cdh5.7.0
    export PATH=$HIVE_HOME/bin:$PATH
    ```

2. 配置 hive-env.sh

    ```conf
    HADOOP_HOME=/home/wst/apps/hadoop-2.6.0-cdh5.7.0
    ```

3. 配置 hive-site.xml

```xml
<configuration>
    <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>1</value>
      <description>password to use against metastore database</description>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://192.168.8.169:3306/hive_sparksql?createDatabaseIfNotExist=true&amp;useSSL=true</value>
      <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
      <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>root</value>
      <description>Username to use against metastore database</description>
    </property>
</configuration>
```

4. 启动 hive


## 使用 hive

1. hive官方建表语句：

  ```sql
  CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)
    [(col_name data_type [COMMENT col_comment], ... [constraint_specification])]
    [COMMENT table_comment]
    [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
    [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
    [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
      ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
      [STORED AS DIRECTORIES]
    [
    [ROW FORMAT row_format] 
    [STORED AS file_format]
      | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)
    ]
    [LOCATION hdfs_path]
    [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)
    [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)
  
  CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
    LIKE existing_table_or_view_name
    [LOCATION hdfs_path];
  
  data_type
    : primitive_type
    | array_type
    | map_type
    | struct_type
    | union_type  -- (Note: Available in Hive 0.7.0 and later)
  
  primitive_type
    : TINYINT
    | SMALLINT
    | INT
    | BIGINT
    | BOOLEAN
    | FLOAT
    | DOUBLE
    | DOUBLE PRECISION -- (Note: Available in Hive 2.2.0 and later)
    | STRING
    | BINARY      -- (Note: Available in Hive 0.8.0 and later)
    | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)
    | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)
    | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)
    | DATE        -- (Note: Available in Hive 0.12.0 and later)
    | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)
    | CHAR        -- (Note: Available in Hive 0.13.0 and later)
  
  array_type
    : ARRAY < data_type >
  
  map_type
    : MAP < primitive_type, data_type >
  
  struct_type
    : STRUCT < col_name : data_type [COMMENT col_comment], ...>
  
  union_type
    : UNIONTYPE < data_type, data_type, ... >  -- (Note: Available in Hive 0.7.0 and later)
  
  row_format
    : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]
          [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
          [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)
    | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]
  
  file_format:
    : SEQUENCEFILE
    | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
    | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
    | ORC         -- (Note: Available in Hive 0.11.0 and later)
    | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
    | AVRO        -- (Note: Available in Hive 0.14.0 and later)
    | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)
    | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
  
  constraint_specification:
    : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE ]
      [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES table_name(col_name, ...) DISABLE NOVALIDATE 
  ```

2. 基本建表语句

  ```sql
  create table hive_wordcount()
  ```

3. 将如下内容放入hive表中：

  ```
  ➜  data cat emp.txt
  7369	SMITH	CLERK	7902	1980-12-17	800.00		20
  7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30
  7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30
  7566	JONES	MANAGER	7839	1981-4-2	2975.00		20
  7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30
  7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30
  7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10
  7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20
  7839	KING	PRESIDENT		1981-11-17	5000.00		10
  7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30
  7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20
  7900	JAMES	CLERK	7698	1981-12-3	950.00		30
  7902	FORD	ANALYST	7566	1981-12-3	3000.00		20
  7934	MILLER	CLERK	7782	1982-1-23	1300.00		10
  8888	HIVE	PROGRAM	7839	1988-1-23	10300.00    	
  ```

  ```
  ➜  data cat dept.txt 
  10      ACCOUNTING      NEW YORK
  20      RESEARCH        DALLAS
  30      SALES   CHICAGO
  40      OPERATIONS      BOSTON
  ```

4. 创建 emp 表和 dept 表：

```sql
create table emp(
  empno int,
  ename string,
  job string,
  mgr int,
  hiredate string,
  sal double,
  comm double,
  deptno int
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
```

```sql
create table dept(
  deptno int,
  dname string,
  location string
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
```

5. 加载数据到 emp 表和 dept 表：

```sql
load data local inpath '/home/wst/apps/packages/data/emp.txt' into table emp;
load data local inpath '/home/wst/apps/packages/data/dept.txt' into table dept;

load data local inpath '/mnt/home/1015146591/jars/data/emp.txt' into table emp;
load data local inpath '/mnt/home/1015146591/jars/data/dept.txt' into table dept;
```