## 大数据处理流程

MapReduce：

    input -> map/reduce -> output

Storm:

    input -> Spout/Bolt -> output

Spark:

    input -> transformation/action -> output

[Flink:](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/api_concepts.html)

    input -> transformation/sink -> output

处理过程类似，都是从源头获取数据，进行处理后输出，只不过处理的方式方法不同。 

## [DataSet 和 DataStream](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/api_concepts.html#dataset-and-datastream)

DataSet 用于处理批数据（有界的数据），DateStream 用于处理流数据（无界的数据）。

注意 DataSet 和 DataStream 是不可变的（immutable）。

## [Flink 编程模型](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/api_concepts.html#anatomy-of-a-flink-program)

1. Obtain an execution environment, 获取执行环境

1. Load/create the initial data, 获取数据

1. Specify transformations on this data, 转换数据

1. Specify where to put the results of your computations, 指定输出位置

1. Trigger the program execution 触发执行（批处理不需要）

具体参考 [Anatomy of a Flink Program](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/api_concepts.html#anatomy-of-a-flink-program).





