## Hadoop2.0 产生背景

- Hadoop1.0 中 `HDFS` 和 `MapReduce` 在高可用、扩展性方面存在问题。

- `HDFS` 存在的问题：

    - Namenode单点故障问题 ---> HA

    - NameNode压力过大问题，且内存受限，影响扩展 ---> YARN

- `MapReduce` 存在的问题：

    - JobTracker 访问压力大，影响系统扩展性

    - 难以支持除 MapReduce 之外的计算框架，如 Spark、Storm等。

## Hadoop2.x 和 Hadoop1.x

![1](https://github.com/jiaoqiyuan/pics/raw/master/sxt/hadoop1.x2.x.png)

可以看到 Hadoop2.x 是在 Hadoop1.x 基础上添加了 YARN，从而支持了更多的计算框架，同时将 namenode 从繁重的任务重解脱出来，不在负责任务调度任务，转而由 YARN 进行任务调度的管理。

## HDFS2.x

HDFS2.x 解决了 HDFS1.x中单点故障和内存受限的问题。

- 单点故障问题通过 HDFS HA 解决，通过主备 NameNode 方式，如果主 NameNode 发生故障，则切换到备 NameNode 上。这里牵扯到有主从 NameNode 元数据同步问题。

- 内存受限的问题：

    - HDFS Federation (联邦)

    - 水平扩展，支持多个NameNode

        - 每个 NameNode分管一部分目录

        - 所有 NameNode 共享所有 DataNode 存储资源

- 2.x 仅是架构上发生了变化，使用方式不变。

## Hadoop HA

![2](https://github.com/jiaoqiyuan/pics/raw/master/sxt/hadoop-ha.png)

上面图中展示的 `HA` 是基于 ZooKeeper 实现的自动切换 NameNode 节点的高可用性系统, 该系统下有两个 `NameNode`, 二者之间的切换是通过 ZooKeeper 操作的。

这里的高可用性实现思路是设置两个 NameNode ，一主一从，正常情况下主 NameNode 负责管理 HDFS 上的元数据信息，当主 NameNode 节点出现故障时，由 Zookeeper 切换到从 NameNode 继续提供服务，此时从 NameNode 就变为了主 NameNode，然后由相关人员修复之前坏掉的 NameNode。这两个 NameNode 需要经常同步信息，保证二者的内容尽可能时一致的，以免主 NameNode 出现问题切换到从 NameNode 时二者信息不一致导致的数据丢失问题。

客户端通过主 NameNode 操作数据，由客户端操作产生的数据信息只会记录到主 NameNode 中，要想主从 NameNode 数据保持一致，就需要一种主从 NameNode 的同步机制。

这里使用的同步机制就是 JournalNodes (日志节点) ，如果采用同步阻塞机制，中间数据传输过程中可能出现网络波动问题，导致阻塞不能返回结果而失败的问题，为了一致性破坏了可用性，所以阻塞的同步机制不能采用。

