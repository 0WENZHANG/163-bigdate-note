# MR实现关联操作

## 需求案例

MR的关联操作就是SQL中的JOIN操作,假设有两种存放在HDFS上的两张表:

订单表:

| 订单ID | 用户ID | 商品ID |
|:-----:|:------:|:-----:|
| 100234 | 23942 | 209304 |
| 100235 | 24563 | 248793 |
| 100453 | 25634 | 248793 |
| 100587 | 28867 | 285760 |


商品表:

| 商品ID | 商品名称 | 商品价格 |
|:-----:|:------:|:-----:|
| 209304 | Python入门 | 299 |
| 248793 | 跟我一起学PPT | 29 |gf
| 285760 | 大数据开发 | 599 |

最后需要得到一个商品详情表:

| 订单ID | 用户ID | 商品ID | 商品名称 |
|:-----:|:------:|:-----:|:-------:|
| 100234 | 23942 | 209304 | Python入门 |
| 100235 | 24563 | 248793 | 跟我一起学PPT |
| 100453 | 25634 | 248793 | 跟我一起学PPT |
| 100587 | 28867 | 285760 | 大数据开发 |

## Map Join

- 将关联的其中的一个文件(小文件)放到分布式缓存,将关联的ID作为Key值存为HashMap.

- 将关联中的另一个文件(大文件)划分到各个Map,每个Map里访问分布式缓存,根据关联的ID获取相应的数据.

```mermaid
graph LR
Small_table_file --> Job
Distribute_Cache --> Map1
Distribute_Cache --> Map2
Distribute_Cache --> Map3
Job --> Map1
Job --> Map2
Job --> Map3
Job --> Distribute_Cache

Map1 --> Output1
Map2 --> Output2
Map3 --> Output3
```

[MapJoin示意图][1]

- MR启动时可以将HDFS上的小文件放到分布式缓存中,也就是Distribute Cache中.

- 大文件会被分成一个个数据分片由多个Map进行处理.

- 每个Map都会访问分布式缓存中的数据,然后在Map中将两个表关联起来.

- 最后直接输出结果.

问题:但是如果关联的两个表都比较大,这种方法容易导致内存溢出.

改进措施:根据MR的特性,将两个表相同的需要关联的Key值分配到同一个节点上进行关联.

## Reducer Join

- 将两个关联的文件都划分到各个Map中,并对每一条数据打上属于哪个关联文件的标记,然后将关联的ID作为Map输出的Key值传给Reduce端,这样一来,两张表中相同的key值就会分配到同一个Redece端.

- 在Reduce端将相同的Key值的数据关联起来.

[Reduce Join][2]

## 一对多关联的优化

- 使用二次排序,对数据表标识符排序,避免将数据多的那张表的数据缓存在内存中.减少内存使用,避免OOM(Out of Memory)

## 总结

- Map Join

    适用于小表关联大表,运行效率高

- Reduce Join

    通用关联方法,可能发生数据倾斜.

[1]:
[2]:

