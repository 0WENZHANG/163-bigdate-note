# Hadoop的IO模型-下

实际应用场景中要解析的字段一般都会很多，如果全部都重写一遍序列化操作工作量会很大，可以编写一个通用的序列化接口来避免重复编写序列化代码。可以考虑以下方法：

- 使用map，将所有字段都存放到map中，然后将map传递到reduce端，而且Hadoop框架也提供有MapWritable类型。但是这里有个问题，map是将key值和value值一起存放到map中，每次传输都会把key值信息也传递出去，但其实key值的信息是固定范围内的那些字段值：device_id,ip,order_ip...等。这会造成大量的网络浪费。不过这种方式编程简单，只需要把值放入这个map集合中的即可。

- 只传输value值，，不传输key值。可以使用array将这些value值传输端，但是需要保证每一个value值的相对位置是一定的，不能发生错乱，否则会导致解析错乱。可以自定义一个通用类实现这个功能。




